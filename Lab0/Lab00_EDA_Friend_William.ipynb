{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0613bce",
   "metadata": {},
   "source": [
    "# Lab0 - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021e8f9",
   "metadata": {},
   "source": [
    "Imagine we are interested in predicting breast cancer (benign or maligant). First we want to do some\n",
    "data exploration to get a feel for the data.\n",
    "\n",
    "Source: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8212853",
   "metadata": {},
   "source": [
    "## 0: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. import libraries\n",
    "# your source code below\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import warnings library\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d4daa",
   "metadata": {},
   "source": [
    "## 1. Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 read the data into dataframe from the csv file breast_cancer.csv\n",
    "# your source code below\n",
    "df = pd.read_csv('breast_cancer.csv' #df is equals to the dataframe, and the dataframe is equal to the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4340699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Show a few samples of the data  hint: use head().\n",
    "# your source code below\n",
    "print(df.head()) #print the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Display the information data such as each column's type, non-null information hint: use info().\n",
    "# your source code below\n",
    "print(df.info()) # print the information of the dataframe, by information it means the data type of each column, and the number of non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586a7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.4 Display the summary information of data such mean and standard deviation. hint: use describe().\n",
    "# your source code below\n",
    "print(df.describe()) # print the summary of the dataframe, by summary it means the mean, std, min, max, etc of each column it wont work the way we want without first cleaning the data though which we will do in 2.1\n",
    "# because of columns we will drop soon, we are getting mostly nans for the mean and std, etc, this is due to the Unamed: 32 column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9be89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 print out the label count for each classification. hint: use value_counts().\n",
    "# your source code below\n",
    "#We will get the count of each label in the diagnosis column, to see how many malignant and benign cases we have\n",
    "print(df['diagnosis'].value_counts()) # print the count of each label in the diagnosis column, diagnosis is the column name, and value_counts() is the function that will count the number of each label in the column\n",
    "# I choose diagnosis because it is the column that we are trying to predict, and it is the column that we will be using to train our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437d525",
   "metadata": {},
   "source": [
    "## 2. Process Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c62cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 drop the columns of ['Unnamed: 32','id'] from the dataframe hint: use drop()\n",
    "# your source code below\n",
    "df = df.drop(columns=['Unnamed: 32', 'id'], errors='ignore') # drop the columns of ['Unnamed: 32','id'] from the dataframe, errors='ignore' is used to ignore the error that would be thrown if we tried to drop a column that was already dropped\n",
    "# now that we have dropped the columns, we can print the head again to see the changes\n",
    "# now we get valuable information about the data instead of a bunch of nans\n",
    "print(df.describe()) # print the summary of the dataframe, by summary it means the mean, std, min, max, etc of each column, now after being cleaned, we can see the mean, std, min, max, etc of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cf8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 store the feature names as a list, and print it out\n",
    "# your source code below\n",
    "# Store the feature names as a list\n",
    "feature_names = df.columns.tolist() # feature_names is equal to the columns of the dataframe, and tolist() is used to convert the columns into a list\n",
    "\n",
    "# Print it out\n",
    "print(feature_names) # print the feature names, feature_names is equal to the columns of the dataframe, and tolist() is used to convert the columns into a list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed347b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 construct X and y, so that:\n",
    "# - X holds all data information except label column (i.e., diagnosis)\n",
    "# - y hold the data label column (i.e., diagnosis)\n",
    "#  !!! you still keep your original dataframe for later use !!!\n",
    "# print out the shapes of the dataframe, X and y\n",
    "# your source code below\n",
    "\n",
    "# Constructing X and y\n",
    "# the 30 without the last column\n",
    "X = df.drop(columns=['diagnosis']) # X is equal to the dataframe, and the dataframe is equal to the csv file, and we are dropping the diagnosis column because that is the column\n",
    "# the last column\n",
    "y = df['diagnosis'] # y is equal to the dataframe, and the dataframe is equal to the csv file, and we are only keeping the diagnosis column because that is the column\n",
    "\n",
    "# Printing out the shapes of the dataframe, X, and y\n",
    "# i used format strings to make it easier to read\n",
    "print(f\"Shape of dataframe: {df.shape}\") # print the shape of the dataframe\n",
    "print(f\"Shape of X: {X.shape}\") # print the shape of X\n",
    "print(f\"Shape of y: {y.shape}\") # print the shape of y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9511550",
   "metadata": {},
   "source": [
    "## 3. Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1: Plot histograms for X (all 30 features) hint: use subplots and histograms\n",
    "# make sure your subplots should be well spaced\n",
    "# your source code below\n",
    "\n",
    "# # Find out how many features we have\n",
    "n_features = X.shape[1] # shape returns a tuple (n_rows, n_columns), in this case, (569, 30)\n",
    "# I want this readable so we will put 5 features, (since we are dealing with 30 it could just as easily be 6), or 2 and 15, or 1  and 30, etc \n",
    "# or histograms, per row\n",
    "#n_cols = 6\n",
    "n_cols = 5 # n_cols is equal to 5\n",
    "\n",
    "# I need to calculate how many row I will need for subplots\n",
    "# n_rows = (n_features // n_cols) + 1\n",
    "n_rows = (n_features + n_cols - 1) // n_cols  # n_rows is equal to the number of features plus the number of columns minus 1, divided by the number of columns\n",
    "\n",
    "# I need to set the spacing between the subplots so they are readable. \n",
    "# Ill go 15 by 15 and I can go bigger later if necessary\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 15)) # fig is equal to the figure, and the figure is equal to the number of rows, number of columns, and the size of the figure\n",
    "\n",
    "# I need to add space between the subplots so they are readable\n",
    "fig.subplots_adjust(hspace=1.0, wspace=1.0) # fig is equal to the figure, and the figure is equal to the space between the subplots\n",
    "\n",
    "# For each individual feature, I want to draw a histogram\n",
    "for i, column in enumerate(X.columns):\n",
    "    # Figure out each histogram should go\n",
    "    row = i // n_cols # row is equal to the index of the feature divided by the number of columns\n",
    "    col = i % n_cols # col is equal to the index of the feature modulo the number of columns\n",
    "\n",
    "    # Draw the histogram for each feature\n",
    "    axes[row, col].hist(X[column], bins=20, color='blue', alpha=0.5) # axes is equal to the row and column we calculated above, and we are drawing a histogram with 20 bins, blue, and 50% transparency\n",
    "    \n",
    "    # Dynamically add title so we know which feature goes with which plot\n",
    "    axes[row, col].set_title(column) # axes is equal to the row and column we calculated above, and we are setting the title to the name of the feature\n",
    "    # Label the x and y axes\n",
    "    axes[row, col].set_xlabel('Value') # axes is equal to the row and column we calculated above, and we are setting the x label to Value\n",
    "    axes[row, col].set_ylabel('Frequency') # axes is equal to the row and column we calculated above, and we are setting the y label to Frequency\n",
    "\n",
    "# If we have some empty space left in our grid (like if we have 27 features and are using a 5x6 grid)\n",
    "# then we want to hide these empty plots\n",
    "for j in range(i+1, n_rows*n_cols): # j is equal to the index of the feature plus 1, and we are looping through the number of rows times the number of columns\n",
    "    axes[j // n_cols, j % n_cols].axis('off') # axes is equal to the index of the feature divided by the number of columns, and the index of the feature modulo the number of columns, and we are turning off the axis\n",
    "\n",
    "# badabing badaboom, now I draw the plot and presto\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d353893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2: do pairplot for the first five columns in data matrix\n",
    "# hint: using seaborn.pairplot, and use hue ='diagnosis'\n",
    "# make sure you only extract the first five columns\n",
    "\n",
    "# your source code below\n",
    "\n",
    "# I want to make a subset of the dataframe that only has the first 5 columns\n",
    "# subset_df is a dataframe that only has the first 5 columns\n",
    "# df.iloc[:, :5] means I want all rows, and all columns up to but not including the 5th column\n",
    "subset_df = df.iloc[:, :5]\n",
    "\n",
    "#check to make sure it worked\n",
    "#print(subset_df.head())\n",
    "\n",
    "# With sns.pairplot, I can make a pairplot of the first 5 columns,\n",
    "# giving the parameter hue='diagnosis' will color the points based on the diagnosis\n",
    "# giving the parameter diag_kind='hist' will make the diagonal plots histograms\n",
    "# I could have used the standard curve, but I think the histogram is more informative\n",
    "# to change the color palette, I can give the parameter palette='husl' or any other color palettes like 'viridis', 'magma', etc\n",
    "# to change the scatter plot to a histogram, I can give the parameter kind='hist', but I prefer the scatter plot\n",
    "sns.pairplot(subset_df, hue='diagnosis', palette='magma', kind='hist')\n",
    "\n",
    "# badabing badaboom show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8333e8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
